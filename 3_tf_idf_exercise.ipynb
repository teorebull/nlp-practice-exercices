{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVrcHNZpQLUz"
   },
   "source": [
    "### **TF-IDF: Exercises**\n",
    " \n",
    "- Humans ðŸ‘¦ show different emotions/feelings based on the situations and communicate them through facial expressions or in form of words.\n",
    " \n",
    "- In Social Media like Twitter and Instagram, many people express their views through comments about a particular event/scenario and these comments may address the feelings like sadness, happiness, joy, sarcasm, fear, and many other.\n",
    " \n",
    "- For a given comment/text, we are going to use classical NLP techniques and classify under which emotion that particular comment belongs!\n",
    " \n",
    "- We are going to use techniques like Bag of grams, n-grams, TF-IDF, etc. for text representation and apply different classification algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wU5KDovsV9ez"
   },
   "source": [
    "### **About Data: Emotion Detection**\n",
    "\n",
    "Credits: https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp\n",
    "\n",
    "\n",
    "- This data consists of two columns.\n",
    "        - Comment\n",
    "        - Emotion\n",
    "- Comment are the statements or messages regarding to a particular event/situation.\n",
    "\n",
    "- Emotion feature tells whether the given comment is fear ðŸ˜¨, Anger ðŸ˜¡, Joy ðŸ˜‚.\n",
    "\n",
    "- As there are only 3 classes, this problem comes under the **Multi-Class Classification.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "8ML2s0KWVXmv",
    "outputId": "4284d452-b3f4-4998-a2bf-9fd7aa273207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15999, 2)\n",
      "                                                text  emotion\n",
      "0  i can go from feeling so hopeless to so damned...  sadness\n",
      "1   im grabbing a minute to post i feel greedy wrong    anger\n",
      "2  i am ever feeling nostalgic about the fireplac...     love\n",
      "3                               i am feeling grouchy    anger\n",
      "4  ive been feeling a little burdened lately wasn...  sadness\n"
     ]
    }
   ],
   "source": [
    "#import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "#read the dataset with name \"Emotion_classify_Data.csv\" and store it in a variable df\n",
    "df = pd.read_csv(r'C:\\Users\\teore\\OneDrive\\Documents\\GitHub\\NLP_tutorial\\tf_idf\\train.txt', sep=';')\n",
    "\n",
    "#print the shape of dataframe\n",
    "print(df.shape)\n",
    "df.columns = ['text', 'emotion']\n",
    "#print top 5 rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "joLuZmFpT-fY",
    "outputId": "77d48614-f6b3-4227-e90e-dc8ddb17381b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "joy         5362\n",
       "sadness     4665\n",
       "anger       2159\n",
       "fear        1937\n",
       "love        1304\n",
       "surprise     572\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the distribution of Emotion\n",
    "df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "qPxiqT_TT-hx",
    "outputId": "d58985b6-c81c-48b5-de9b-74735bb6b133"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  emotion  emotion_num\n",
      "0  i can go from feeling so hopeless to so damned...  sadness            1\n",
      "1   im grabbing a minute to post i feel greedy wrong    anger            2\n",
      "2  i am ever feeling nostalgic about the fireplac...     love            4\n",
      "3                               i am feeling grouchy    anger            2\n",
      "4  ive been feeling a little burdened lately wasn...  sadness            1\n"
     ]
    }
   ],
   "source": [
    "#Add the new column \"Emotion_num\" which gives a unique number to each of these Emotions\n",
    "#joy --> 0, fear --> 1, anger --> 2\n",
    "df[\"emotion_num\"] = df['emotion'].map({'joy': 0, 'sadness': 1 , 'anger': 2 , 'fear': 3 , 'love': 4 , 'surprise': 5})\n",
    "\n",
    "#checking the results by printing top 5 rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PE-c0zbDXTEm"
   },
   "source": [
    "### **Modelling without Pre-processing Text data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "NjJqi7UBT-nr"
   },
   "outputs": [],
   "source": [
    "#import train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Do the 'train-test' splitting with test size of 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['emotion_num'], test_size = 0.2, random_state = 2022, stratify=df['emotion_num'])\n",
    "#Note: Give Random state 2022 and also do the stratify sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5lAD0iqGcdCn",
    "outputId": "4efb3c3c-0ad4-4501-d815-35a902095848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12799,)\n",
      "(3200,)\n"
     ]
    }
   ],
   "source": [
    "#print the shapes of X_train and X_test\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t57hw7gOVXuW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6h8ZZLxZd79"
   },
   "source": [
    "\n",
    "**Attempt 1** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with only trigrams.\n",
    "- use **RandomForest** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGg2iXv6g40l",
    "outputId": "3f895ca5-7606-4220-b9a2-7c26d9160a9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89      1073\n",
      "           1       0.91      0.90      0.91       933\n",
      "           2       0.87      0.83      0.85       432\n",
      "           3       0.86      0.82      0.84       387\n",
      "           4       0.87      0.73      0.79       261\n",
      "           5       0.79      0.72      0.75       114\n",
      "\n",
      "    accuracy                           0.87      3200\n",
      "   macro avg       0.86      0.82      0.84      3200\n",
      "weighted avg       0.87      0.87      0.87      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import CountVectorizer, RandomForest, pipeline, classification_report from sklearn \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#1. create a pipeline object\n",
    "rf = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('random_forest', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I08-kc_JYCNL"
   },
   "source": [
    "\n",
    "**Attempt 2** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with both unigram and bigrams.\n",
    "- use **Multinomial Naive Bayes** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8zetSmBrXmjM",
    "outputId": "b372f53c-8cbc-496f-ef4d-9fecff044230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.95      0.82      1073\n",
      "           1       0.72      0.94      0.81       933\n",
      "           2       0.92      0.55      0.69       432\n",
      "           3       0.90      0.56      0.69       387\n",
      "           4       0.91      0.22      0.36       261\n",
      "           5       0.86      0.05      0.10       114\n",
      "\n",
      "    accuracy                           0.75      3200\n",
      "   macro avg       0.84      0.54      0.58      3200\n",
      "weighted avg       0.79      0.75      0.72      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import CountVectorizer, RandomForest, pipeline, classification_report from sklearn \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#1. create a pipeline object\n",
    "nb = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Wde4r_-YwU-"
   },
   "source": [
    "\n",
    "**Attempt 3** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with both unigram and Bigrams.\n",
    "- use **RandomForest** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n0dG2tc0X7SK",
    "outputId": "f6eddad9-a55b-4fde-eea2-2cbc002f6d4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88      1073\n",
      "           1       0.91      0.90      0.91       933\n",
      "           2       0.91      0.79      0.85       432\n",
      "           3       0.89      0.77      0.83       387\n",
      "           4       0.91      0.68      0.78       261\n",
      "           5       0.86      0.66      0.75       114\n",
      "\n",
      "    accuracy                           0.87      3200\n",
      "   macro avg       0.88      0.79      0.83      3200\n",
      "weighted avg       0.87      0.87      0.86      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import CountVectorizer, RandomForest, pipeline, classification_report from sklearn \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#1. create a pipeline object\n",
    "rf = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range = (1,2))),\n",
    "    ('random_forest', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmrXmL_3Z2y6"
   },
   "source": [
    "\n",
    "**Attempt 4** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using **TF-IDF vectorizer** for Pre-processing the text.\n",
    "- use **RandomForest** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djsDsThaaCSO",
    "outputId": "b4514ab2-f6ad-45e1-b91b-e88393e975e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      1073\n",
      "           1       0.91      0.91      0.91       933\n",
      "           2       0.88      0.79      0.83       432\n",
      "           3       0.84      0.82      0.83       387\n",
      "           4       0.85      0.70      0.77       261\n",
      "           5       0.88      0.66      0.75       114\n",
      "\n",
      "    accuracy                           0.86      3200\n",
      "   macro avg       0.87      0.80      0.83      3200\n",
      "weighted avg       0.86      0.86      0.86      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import CountVectorizer, RandomForest, pipeline, classification_report from sklearn \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#1. create a pipeline object\n",
    "rf = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('random_forest', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ACq6pDkZ4sA"
   },
   "source": [
    "<h3>Use text pre-processing to remove stop words, punctuations and apply lemmatization </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "tj_xYgthX7UF"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# load english language model and create nlp object from it\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "\n",
    "#use this utility function to get the preprocessed text data\n",
    "def preprocess(text):\n",
    "    # remove stop words and lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    \n",
    "    return \" \".join(filtered_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "xqW1i19wX7Xq"
   },
   "outputs": [],
   "source": [
    "# create a new column \"preprocessed_comment\" and use the utility function above to get the clean data\n",
    "df[\"preprocessed_comment\"] = df[\"text\"].apply(preprocess)\n",
    "# this will take some time, please be patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q24oRlMcai9l"
   },
   "source": [
    "**Build a model with pre processed text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ahdd2mgxX7dM"
   },
   "outputs": [],
   "source": [
    "#Do the 'train-test' splitting with test size of 20% with random state of 2022 and stratify sampling too\n",
    "#Note: Use the preprocessed_Comment\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['preprocessed_comment'], df['emotion_num'], test_size = 0.2, random_state = 2022, stratify=df['emotion_num'])\n",
    "#Note: Give Random state 2022 and also do the stratify sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqonfpeYasOE"
   },
   "source": [
    "**Let's check the scores with our best model till now**\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1wYgFs3auLQ"
   },
   "source": [
    "**Attempt1** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with both unigrams and bigrams.\n",
    "- use **RandomForest** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Khtu32z1XmmE",
    "outputId": "b5f67051-d0e3-4e2e-e342-8297938090ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89      1073\n",
      "           1       0.86      0.94      0.90       933\n",
      "           2       0.87      0.83      0.85       432\n",
      "           3       0.92      0.82      0.86       387\n",
      "           4       0.80      0.74      0.77       261\n",
      "           5       0.82      0.75      0.78       114\n",
      "\n",
      "    accuracy                           0.87      3200\n",
      "   macro avg       0.86      0.83      0.84      3200\n",
      "weighted avg       0.87      0.87      0.87      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import CountVectorizer, RandomForest, pipeline, classification_report from sklearn \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#1. create a pipeline object\n",
    "rf = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range = (1,2))),\n",
    "    ('random_forest', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9GZPaQbbJbx"
   },
   "source": [
    "\n",
    "**Attempt 2** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the data.\n",
    "\n",
    "**Note:**\n",
    "- using **TF-IDF vectorizer** for pre-processing the text.\n",
    "- use **RandomForest** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2y1Cy4Bauxu",
    "outputId": "ac6bf255-a218-400c-c4a9-790f4a89dfb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87      1073\n",
      "           1       0.89      0.89      0.89       933\n",
      "           2       0.87      0.81      0.84       432\n",
      "           3       0.83      0.83      0.83       387\n",
      "           4       0.82      0.65      0.73       261\n",
      "           5       0.79      0.67      0.72       114\n",
      "\n",
      "    accuracy                           0.85      3200\n",
      "   macro avg       0.84      0.79      0.81      3200\n",
      "weighted avg       0.85      0.85      0.85      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import CountVectorizer, RandomForest, pipeline, classification_report from sklearn \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#1. create a pipeline object\n",
    "rf = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('random_forest', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Please write down Final Observations**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ta2cWBUkfKel"
   },
   "source": [
    "## [**Solution**](./tf_idf_exercise_solutions.ipynb)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tf_idf_exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
